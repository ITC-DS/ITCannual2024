\subsection{大規模言語モデルの研究とその応用(Li Zihui）}

% Educational Large Language Models (LLMs): This research area focuses on enhancing the discovery of educational resources and the interpretability of transformer models in NLP education. We explored whether traditional methods could effectively identify high-quality study materials and proposed a transfer learning-based pipeline to improve resource discovery, especially for generating introductory paragraphs in educational content \cite{ireneli-3,ireneli-9}. Additionally, we assessed the potential of LLMs as tools for learning support, presenting a benchmark to evaluate their performance in various NLP tasks \cite{ireneli-5}. Our investigation also included the generation of concise survey articles in the NLP domain using LLMs. While GPT-created surveys were found to be more up-to-date and accessible than human-written ones, some limitations, such as occasional factual inaccuracies, were noted \cite{ireneli-11}. Furthermore, we explored the use of LLMs in teaching complex legal concepts through narrative methods \cite{ireneli-8}. Our LLM research works \cite{ireneli-1} have been noticed by \textbf{Nature News}, and I had the opportunity to be interviewed by a reporter, where I shared my insights on the impact of Large Language Models (LLMs) from the academia perspective \cite{ireneli-13}.

% Medical Large Language Models (LLMs): In medical LLM research, we focus on enhancing LLMs' capabilities in medical question answering and teaching complex legal concepts via storytelling. Collaborating with MatsuoLab, we developed a framework combining knowledge graphs and ranking techniques to boost LLMs' effectiveness in medical queries \cite{ireneli-7}. We also introduced Ascle, a Python NLP toolkit for medical text generation \cite{ireneli-10}.

% Other Benchmarks for NLP Open Questions: Our research extends to improving knowledge graph completion, evaluating LLMs in NLP problem-solving, and developing medical text generation tools. We investigated the enhancement of knowledge graph completion using node neighborhood data \cite{ireneli-4} and explored methods to better interpret transformer models by emphasizing crucial information \cite{ireneli-6}. Besides, we have been investigating other branches including graph methods for news encoding \cite{ireneli-2,ireneli-12}.


This year’s research focused on three main areas: advancing clinical NLP tools and decision support, developing explainable and adaptive recommendation systems, and improving factual reasoning in language models using knowledge graphs. Across journals, conferences, and workshops, these works contributed novel methods and practical frameworks for enhancing AI reliability, personalization, and interpretability in healthcare and information systems.

In the medical AI domain, Ascle was introduced as an open-source NLP toolkit for medical text generation, offering fine-tuned models and user-friendly APIs to support structured content creation in clinical settings \cite{ireneli-1}. A simulation study demonstrated the effectiveness of multi-agent LLM conversations in reducing cognitive biases in clinical decision-making. Additionally, a comparative analysis of pretraining methods for chest radiograph classification showed that task-specific self-supervised models outperform standard baselines in low-label regimes\cite{ireneli-2,ireneli-3}.

For recommendation systems, one study proposed topic-centric explanations to improve the transparency of news recommendations by linking articles to user-relevant topic distributions \cite{ireneli-4}. Another work introduced RecPrompt, a self-tuning prompting framework that leverages LLMs to dynamically optimize news recommendations based on user preferences, achieving strong performance without additional model training \cite{ireneli-5}.

In the area of factual reasoning, GraphCheck presented a fact-checking framework that uses knowledge graphs extracted from text to support long-context verification \cite{ireneli-6}, particularly effective in medical and general domains. Graphusion proposed a retrieval-augmented generation (RAG) framework for zero-shot knowledge graph construction, supporting downstream tasks like subgraph completion. A related study applied knowledge graph-based RAG to Japanese medical QA, highlighting both the promise and current limitations in low-resource, domain-specific applications \cite{ireneli-7,ireneli-8}.
